{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a185b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/01_data_ingestion_and_cleaning.ipynb\n",
    "\n",
    "# Cell 1: Setup and Imports\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd \n",
    "\n",
    "# Add the 'src' directory to the Python path\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from src.data_loader import load_data_from_csv, load_data_from_postgres, download_kaggle_dataset\n",
    "from src.data_cleaner import clean_telco_data\n",
    "from src.utils import logger, get_output_base_path\n",
    "\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1578dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Initialize Output Paths for this Run\n",
    "output_base_path_for_run = get_output_base_path(project_root)\n",
    "logger.info(f\"All pipeline outputs for this run will be saved under: {output_base_path_for_run}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54128eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Download Raw Data from Kaggle (THIS IS THE CELL YOU NEED TO ADD/ENSURE IS PRESENT)\n",
    "kaggle_dataset_name = \"blastchar/telco-customer-churn\"\n",
    "data_folder_path = os.path.join(project_root, 'data') # This is where the CSV will be saved\n",
    "\n",
    "# This function will attempt to download the dataset if it's not already there\n",
    "# and return the path to the downloaded CSV file.\n",
    "downloaded_csv_path = download_kaggle_dataset(kaggle_dataset_name, data_folder_path)\n",
    "\n",
    "if downloaded_csv_path:\n",
    "    logger.info(f\"Kaggle dataset available/downloaded at: {downloaded_csv_path}\")\n",
    "    # Now that we know the path, we can use it in the next cell\n",
    "    csv_file_path = downloaded_csv_path\n",
    "else:\n",
    "    logger.error(\"Failed to ensure Kaggle dataset is available. CSV loading might fail.\")\n",
    "    csv_file_path = os.path.join(data_folder_path, 'WA_Fn-UseC_-Telco-Customer-Churn.csv') # Fallback path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c42a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Data Ingestion (CSV)\n",
    "csv_file_path = os.path.join(project_root, 'data', 'WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "telco_df_raw = load_data_from_csv(csv_file_path, output_base_path=output_base_path_for_run)\n",
    "\n",
    "if telco_df_raw is not None:\n",
    "    logger.info(f\"Raw DataFrame loaded successfully with shape: {telco_df_raw.shape}\")\n",
    "else:\n",
    "    logger.error(\"Failed to load raw data from CSV. Check previous logs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b8fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Data Cleaning and Transformation\n",
    "if telco_df_raw is not None:\n",
    "    telco_df_cleaned = clean_telco_data(telco_df_raw, output_base_path=output_base_path_for_run)\n",
    "\n",
    "    if telco_df_cleaned is not None:\n",
    "        logger.info(f\"Cleaned DataFrame created successfully with shape: {telco_df_cleaned.shape}\")\n",
    "        logger.info(f\"Final check: Number of missing values after cleaning:\\n{telco_df_cleaned.isnull().sum().to_string()}\")\n",
    "        logger.info(f\"Final check: 'TotalCharges' dtype: {telco_df_cleaned['TotalCharges'].dtype}\")\n",
    "        logger.info(f\"Final check: 'Churn' unique values: {telco_df_cleaned['Churn'].unique()}\")\n",
    "    else:\n",
    "        logger.error(\"Failed to clean data. Check previous logs.\")\n",
    "else:\n",
    "    logger.warning(\"Skipping data cleaning as raw data loading failed.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa8df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Data Ingestion (PostgreSQL Example - Uses SQL file)\n",
    "# NOTE: This cell requires your PostgreSQL database (telco_insights_db) to be set up\n",
    "#       with the 'customer_churn' table and data loaded into it.\n",
    "#       Only uncomment and run this cell if you are testing the PostgreSQL pathway.\n",
    "\n",
    "if telco_df_raw is None: # Only run if CSV loading failed or skipped\n",
    "    logger.info(\"Attempting to load data from PostgreSQL using a query from file .\")\n",
    "\n",
    "    sql_file_path = os.path.join(project_root, 'sql', 'initial_churn_data.sql')\n",
    "\n",
    "    sql_query_from_file = None\n",
    "    try:\n",
    "        with open(sql_file_path, 'r') as file:\n",
    "            sql_query_from_file = file.read()\n",
    "        logger.info(f\"Successfully loaded SQL query from: {sql_file_path}\")\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Error: SQL file '{sql_file_path}' not found. Please create it.\", exc_info=True)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred while reading SQL file: {e}\", exc_info=True)\n",
    "\n",
    "    if sql_query_from_file:\n",
    "        telco_df_sql_raw = load_data_from_postgres(query=sql_query_from_file,\n",
    "                                                    output_base_path=output_base_path_for_run)\n",
    "\n",
    "        if telco_df_sql_raw is not None:\n",
    "            logger.info(f\"Raw DataFrame loaded from PostgreSQL successfully with shape: {telco_df_sql_raw.shape}\")\n",
    "        else:\n",
    "            logger.error(\"Failed to load raw data from PostgreSQL. Check previous logs.\")\n",
    "    else:\n",
    "        logger.error(\"Skipping PostgreSQL data load as SQL query could not be loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5364dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Save Cleaned Data\n",
    "# Assuming output_base_path_for_run and logger are already defined in previous cells\n",
    "\n",
    "if telco_df_cleaned is not None:\n",
    "    # Define the output path for the cleaned data\n",
    "    cleaned_data_output_dir = os.path.join(output_base_path_for_run, 'processed_data')\n",
    "    os.makedirs(cleaned_data_output_dir, exist_ok=True) # Create directory if it doesn't exist\n",
    "\n",
    "    cleaned_data_file_path = os.path.join(cleaned_data_output_dir, 'telco_customer_churn_cleaned.parquet')\n",
    "\n",
    "    try:\n",
    "        telco_df_cleaned.to_parquet(cleaned_data_file_path, index=False)\n",
    "        logger.info(f\"Cleaned data successfully saved to: {cleaned_data_file_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save cleaned data to Parquet: {e}\", exc_info=True)\n",
    "\n",
    "    # You could also save as CSV if preferred, for broader compatibility:\n",
    "    # cleaned_data_csv_file_path = os.path.join(cleaned_data_output_dir, 'telco_customer_churn_cleaned.csv')\n",
    "    # try:\n",
    "    #     telco_df_cleaned.to_csv(cleaned_data_csv_file_path, index=False)\n",
    "    #     logger.info(f\"Cleaned data also saved to CSV: {cleaned_data_csv_file_path}\")\n",
    "    # except Exception as e:\n",
    "    #     logger.error(f\"Failed to save cleaned data to CSV: {e}\", exc_info=True)\n",
    "\n",
    "else:\n",
    "    logger.warning(\"Skipping saving cleaned data as no cleaned DataFrame was found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
