{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30a185b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 16:29:27,255 - root - INFO - Logging setup complete.\n"
     ]
    }
   ],
   "source": [
    "# notebooks/01_data_ingestion_and_cleaning.ipynb\n",
    "\n",
    "# Cell 1: Setup and Imports\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Add the 'src' directory to the Python path\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from src.data_loader import load_data_from_csv, load_data_from_postgres, download_kaggle_dataset\n",
    "from src.data_cleaner import clean_telco_data\n",
    "from src.utils import logger, get_output_base_path\n",
    "\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1578dcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 16:29:30,629 - root - INFO - Created output directory for this run: c:\\Users\\nikki\\Documents\\telco_insights_project\\output\\2025-06-19_16-29-30_run\n",
      "2025-06-19 16:29:30,633 - root - INFO - All pipeline outputs for this run will be saved under: c:\\Users\\nikki\\Documents\\telco_insights_project\\output\\2025-06-19_16-29-30_run\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Initialize Output Paths for this Run\n",
    "output_base_path_for_run = get_output_base_path(project_root)\n",
    "logger.info(f\"All pipeline outputs for this run will be saved under: {output_base_path_for_run}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54128eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 16:29:35,158 - root - INFO - Attempting to download Kaggle dataset 'blastom/telco-customer-churn' to 'c:\\Users\\nikki\\Documents\\telco_insights_project\\data'...\n",
      "2025-06-19 16:29:37,451 - root - ERROR - Error downloading Kaggle dataset (CLI error): Command '['C:\\\\Users\\\\nikki\\\\Documents\\\\telco_insights_project\\\\.venv\\\\Scripts\\\\kaggle.exe', 'datasets', 'download', '-d', 'blastom/telco-customer-churn', '-p', 'c:\\\\Users\\\\nikki\\\\Documents\\\\telco_insights_project\\\\data', '--unzip']' returned non-zero exit status 1.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nikki\\Documents\\telco_insights_project\\src\\data_loader.py\", line 42, in download_kaggle_dataset\n",
      "    result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\nikki\\anaconda3\\Lib\\subprocess.py\", line 571, in run\n",
      "    raise CalledProcessError(retcode, process.args,\n",
      "subprocess.CalledProcessError: Command '['C:\\\\Users\\\\nikki\\\\Documents\\\\telco_insights_project\\\\.venv\\\\Scripts\\\\kaggle.exe', 'datasets', 'download', '-d', 'blastom/telco-customer-churn', '-p', 'c:\\\\Users\\\\nikki\\\\Documents\\\\telco_insights_project\\\\data', '--unzip']' returned non-zero exit status 1.\n",
      "2025-06-19 16:29:37,455 - root - ERROR - Kaggle CLI Error Output (stdout): 403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/datasets/metadata/blastom/telco-customer-churn\n",
      "\n",
      "2025-06-19 16:29:37,455 - root - ERROR - Kaggle CLI Error Output (stderr): \n",
      "2025-06-19 16:29:37,455 - root - ERROR - Failed to ensure Kaggle dataset is available. CSV loading might fail.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Download Raw Data from Kaggle (THIS IS THE CELL YOU NEED TO ADD/ENSURE IS PRESENT)\n",
    "kaggle_dataset_name = \"blastchar/telco-customer-churn\"\n",
    "data_folder_path = os.path.join(project_root, 'data') # This is where the CSV will be saved\n",
    "\n",
    "# This function will attempt to download the dataset if it's not already there\n",
    "# and return the path to the downloaded CSV file.\n",
    "downloaded_csv_path = download_kaggle_dataset(kaggle_dataset_name, data_folder_path)\n",
    "\n",
    "if downloaded_csv_path:\n",
    "    logger.info(f\"Kaggle dataset available/downloaded at: {downloaded_csv_path}\")\n",
    "    # Now that we know the path, we can use it in the next cell\n",
    "    csv_file_path = downloaded_csv_path\n",
    "else:\n",
    "    logger.error(\"Failed to ensure Kaggle dataset is available. CSV loading might fail.\")\n",
    "    csv_file_path = os.path.join(data_folder_path, 'WA_Fn-UseC_-Telco-Customer-Churn.csv') # Fallback path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c42a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 15:35:23,796 - root - INFO - Attempting to load data from CSV: c:\\Users\\nikki\\Documents\\telco_insights_project\\data\\WA_Fn-UseC_-Telco-Customer-Churn.csv\n",
      "2025-06-19 15:35:23,804 - root - ERROR - Error: The file 'c:\\Users\\nikki\\Documents\\telco_insights_project\\data\\WA_Fn-UseC_-Telco-Customer-Churn.csv' was not found. Please check the path.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nikki\\Documents\\telco_insights_project\\src\\data_loader.py\", line 18, in load_data_from_csv\n",
      "    df = pd.read_csv(file_path)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nikki\\Documents\\telco_insights_project\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nikki\\Documents\\telco_insights_project\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nikki\\Documents\\telco_insights_project\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nikki\\Documents\\telco_insights_project\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1880, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "                   ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nikki\\Documents\\telco_insights_project\\.venv\\Lib\\site-packages\\pandas\\io\\common.py\", line 873, in get_handle\n",
      "    handle = open(\n",
      "             ^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'c:\\\\Users\\\\nikki\\\\Documents\\\\telco_insights_project\\\\data\\\\WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
      "2025-06-19 15:35:23,815 - root - ERROR - Failed to load raw data from CSV. Check previous logs.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Data Ingestion (CSV)\n",
    "csv_file_path = os.path.join(project_root, 'data', 'WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "telco_df_raw = load_data_from_csv(csv_file_path, output_base_path=output_base_path_for_run)\n",
    "\n",
    "if telco_df_raw is not None:\n",
    "    logger.info(f\"Raw DataFrame loaded successfully with shape: {telco_df_raw.shape}\")\n",
    "else:\n",
    "    logger.error(\"Failed to load raw data from CSV. Check previous logs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b8fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Data Cleaning and Transformation\n",
    "if telco_df_raw is not None:\n",
    "    telco_df_cleaned = clean_telco_data(telco_df_raw, output_base_path=output_base_path_for_run)\n",
    "\n",
    "    if telco_df_cleaned is not None:\n",
    "        logger.info(f\"Cleaned DataFrame created successfully with shape: {telco_df_cleaned.shape}\")\n",
    "        logger.info(f\"Final check: Number of missing values after cleaning:\\n{telco_df_cleaned.isnull().sum().to_string()}\")\n",
    "        logger.info(f\"Final check: 'TotalCharges' dtype: {telco_df_cleaned['TotalCharges'].dtype}\")\n",
    "        logger.info(f\"Final check: 'Churn' unique values: {telco_df_cleaned['Churn'].unique()}\")\n",
    "    else:\n",
    "        logger.error(\"Failed to clean data. Check previous logs.\")\n",
    "else:\n",
    "    logger.warning(\"Skipping data cleaning as raw data loading failed.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa8df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Data Ingestion (PostgreSQL Example - Uses SQL file)\n",
    "# NOTE: This cell requires your PostgreSQL database (telco_insights_db) to be set up\n",
    "#       with the 'customer_churn' table and data loaded into it.\n",
    "#       Only uncomment and run this cell if you are testing the PostgreSQL pathway.\n",
    "\n",
    "# if telco_df_raw is None: # Only run if CSV loading failed or skipped\n",
    "#     logger.info(\"Attempting to load data from PostgreSQL using a query from file (Approach #2).\")\n",
    "\n",
    "#     sql_file_path = os.path.join(project_root, 'sql', 'initial_churn_data.sql')\n",
    "\n",
    "#     sql_query_from_file = None\n",
    "#     try:\n",
    "#         with open(sql_file_path, 'r') as file:\n",
    "#             sql_query_from_file = file.read()\n",
    "#         logger.info(f\"Successfully loaded SQL query from: {sql_file_path}\")\n",
    "#     except FileNotFoundError:\n",
    "#         logger.error(f\"Error: SQL file '{sql_file_path}' not found. Please create it.\", exc_info=True)\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"An unexpected error occurred while reading SQL file: {e}\", exc_info=True)\n",
    "\n",
    "#     if sql_query_from_file:\n",
    "#         telco_df_sql_raw = load_data_from_postgres(query=sql_query_from_file,\n",
    "#                                                     output_base_path=output_base_path_for_run)\n",
    "\n",
    "#         if telco_df_sql_raw is not None:\n",
    "#             logger.info(f\"Raw DataFrame loaded from PostgreSQL successfully with shape: {telco_df_sql_raw.shape}\")\n",
    "#         else:\n",
    "#             logger.error(\"Failed to load raw data from PostgreSQL. Check previous logs.\")\n",
    "#     else:\n",
    "#         logger.error(\"Skipping PostgreSQL data load as SQL query could not be loaded.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
